"""
E-Mateå¼ºåŒ–å­¦ä¹ æ¨¡å—åœºæ™¯æµ‹è¯•ç”¨ä¾‹

åŸºäºE-Mateä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½è®¾è®¡çš„ç»¼åˆæµ‹è¯•åœºæ™¯ï¼š
1. æ™ºèƒ½å·¥ä½œä¼™ä¼´
2. ä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶  
3. å·¥ä½œå¥åº·å®ˆæŠ¤è€…

éªŒè¯å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨çœŸå®å·¥ä½œåœºæ™¯ä¸‹çš„å†³ç­–èƒ½åŠ›å’Œå­¦ä¹ æ•ˆæœã€‚
"""

from __future__ import annotations

import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple

from emate.core.contracts import InputState, PerceptionInput, SystemContext, MemoryInput, MemoryEpisode
from emate.core.graph import PersonaDecisionGraph
from emate.memory.memory_manager import MemoryManager
from emate.micro.qlearning import QLearningNode


class RLScenarioTester:
    """
    å¼ºåŒ–å­¦ä¹ åœºæ™¯æµ‹è¯•å™¨
    
    è®¾è®¡å¹¶æ‰§è¡ŒåŸºäºE-Mateæ ¸å¿ƒåŠŸèƒ½çš„æµ‹è¯•åœºæ™¯ï¼Œ
    è¯„ä¼°å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å†³ç­–è´¨é‡å’Œå­¦ä¹ æ•ˆæœã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.decision_graph = PersonaDecisionGraph()
        self.memory_manager = MemoryManager(user_id="test_user")
        self.test_results = []
        
    def run_all_scenario_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰åœºæ™¯æµ‹è¯•"""
        print("ğŸ§  E-Mateå¼ºåŒ–å­¦ä¹ æ¨¡å— - æ ¸å¿ƒåŠŸèƒ½åœºæ™¯æµ‹è¯•")
        print("=" * 70)
        
        results = {
            "intelligent_work_partner": self.test_intelligent_work_partner(),
            "proactive_time_manager": self.test_proactive_time_manager(), 
            "work_health_guardian": self.test_work_health_guardian(),
            "learning_effectiveness": self.test_learning_effectiveness(),
            "summary": self.generate_test_summary()
        }
        
        return results
    
    def test_intelligent_work_partner(self) -> Dict[str, Any]:
        """æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½ä¸€ï¼šæ™ºèƒ½å·¥ä½œä¼™ä¼´"""
        print("\nğŸ“‹ æµ‹è¯•åœºæ™¯ç»„1: æ™ºèƒ½å·¥ä½œä¼™ä¼´")
        print("-" * 50)
        
        scenarios = self._create_work_partner_scenarios()
        results = []
        
        for scenario_name, input_state in scenarios.items():
            print(f"\nğŸ” æµ‹è¯•åœºæ™¯: {scenario_name}")
            
            # æ‰§è¡Œå†³ç­–
            output = self.decision_graph.run_once(input_state)
            
            # è¯„ä¼°å†³ç­–è´¨é‡
            decision_quality = self._evaluate_work_partner_decision(
                scenario_name, input_state, output
            )
            
            result = {
                "scenario": scenario_name,
                "input": self._serialize_input_state(input_state),
                "output_action": output.action.type,
                "tts_response": output.tts_output.text_to_speak,
                "decision_quality": decision_quality,
                "passed": decision_quality["score"] >= 0.7
            }
            
            results.append(result)
            
            # æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆè¿›è¡Œå­¦ä¹ 
            user_feedback = self._simulate_user_feedback(scenario_name, output)
            self.memory_manager.process_interaction(input_state, output.action.type, user_feedback)
            
            print(f"   å†³ç­–: {output.action.type}")
            print(f"   å“åº”: {output.tts_output.text_to_speak}")
            print(f"   è´¨é‡è¯„åˆ†: {decision_quality['score']:.2f}")
            print(f"   ç”¨æˆ·åé¦ˆ: {user_feedback}")
        
        return {
            "category": "æ™ºèƒ½å·¥ä½œä¼™ä¼´",
            "total_scenarios": len(scenarios),
            "passed_scenarios": sum(1 for r in results if r["passed"]),
            "average_score": sum(r["decision_quality"]["score"] for r in results) / len(results),
            "detailed_results": results
        }
    
    def test_proactive_time_manager(self) -> Dict[str, Any]:
        """æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½äºŒï¼šä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶"""
        print("\nâ° æµ‹è¯•åœºæ™¯ç»„2: ä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶")
        print("-" * 50)
        
        scenarios = self._create_time_manager_scenarios()
        results = []
        
        for scenario_name, input_state in scenarios.items():
            print(f"\nğŸ” æµ‹è¯•åœºæ™¯: {scenario_name}")
            
            output = self.decision_graph.run_once(input_state)
            
            decision_quality = self._evaluate_time_manager_decision(
                scenario_name, input_state, output
            )
            
            result = {
                "scenario": scenario_name,
                "input": self._serialize_input_state(input_state),
                "output_action": output.action.type,
                "tts_response": output.tts_output.text_to_speak,
                "decision_quality": decision_quality,
                "passed": decision_quality["score"] >= 0.7
            }
            
            results.append(result)
            
            user_feedback = self._simulate_user_feedback(scenario_name, output)
            self.memory_manager.process_interaction(input_state, output.action.type, user_feedback)
            
            print(f"   å†³ç­–: {output.action.type}")
            print(f"   å“åº”: {output.tts_output.text_to_speak}")
            print(f"   è´¨é‡è¯„åˆ†: {decision_quality['score']:.2f}")
        
        return {
            "category": "ä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶",
            "total_scenarios": len(scenarios),
            "passed_scenarios": sum(1 for r in results if r["passed"]),
            "average_score": sum(r["decision_quality"]["score"] for r in results) / len(results),
            "detailed_results": results
        }
    
    def test_work_health_guardian(self) -> Dict[str, Any]:
        """æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½ä¸‰ï¼šå·¥ä½œå¥åº·å®ˆæŠ¤è€…"""
        print("\nğŸ¥ æµ‹è¯•åœºæ™¯ç»„3: å·¥ä½œå¥åº·å®ˆæŠ¤è€…")
        print("-" * 50)
        
        scenarios = self._create_health_guardian_scenarios()
        results = []
        
        for scenario_name, input_state in scenarios.items():
            print(f"\nğŸ” æµ‹è¯•åœºæ™¯: {scenario_name}")
            
            output = self.decision_graph.run_once(input_state)
            
            decision_quality = self._evaluate_health_guardian_decision(
                scenario_name, input_state, output
            )
            
            result = {
                "scenario": scenario_name,
                "input": self._serialize_input_state(input_state),
                "output_action": output.action.type,
                "tts_response": output.tts_output.text_to_speak,
                "decision_quality": decision_quality,
                "passed": decision_quality["score"] >= 0.7
            }
            
            results.append(result)
            
            user_feedback = self._simulate_user_feedback(scenario_name, output)
            self.memory_manager.process_interaction(input_state, output.action.type, user_feedback)
            
            print(f"   å†³ç­–: {output.action.type}")
            print(f"   å“åº”: {output.tts_output.text_to_speak}")
            print(f"   è´¨é‡è¯„åˆ†: {decision_quality['score']:.2f}")
        
        return {
            "category": "å·¥ä½œå¥åº·å®ˆæŠ¤è€…",
            "total_scenarios": len(scenarios),
            "passed_scenarios": sum(1 for r in results if r["passed"]),
            "average_score": sum(r["decision_quality"]["score"] for r in results) / len(results),
            "detailed_results": results
        }
    
    def test_learning_effectiveness(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼ºåŒ–å­¦ä¹ çš„å­¦ä¹ æ•ˆæœ"""
        print("\nğŸ“ æµ‹è¯•åœºæ™¯ç»„4: å­¦ä¹ æ•ˆæœéªŒè¯")
        print("-" * 50)
        
        # åˆ›å»ºé‡å¤åœºæ™¯æµ‹è¯•å­¦ä¹ æ•ˆæœ
        base_scenario = InputState(
            perception_input=PerceptionInput(
                user_text="æˆ‘éœ€è¦ä¸“æ³¨å®Œæˆå‡¤å‡°é¡¹ç›®ï¼Œä½†æ€»æ˜¯è¢«æ‰“æ–­",
                speech_emotion="stress",
                text_sentiment="negative",
                context_flags=["interruption_high", "important_task", "deadline_near"],
                time_of_day="morning"
            ),
            memory_input=MemoryInput(
                facts=["å‡¤å‡°é¡¹ç›®æ˜¯å…³é”®é¡¹ç›®", "ç”¨æˆ·å®¹æ˜“è¢«å¹²æ‰°æ‰“æ–­"],
                episodes=[]
            ),
            system_context=SystemContext(personality="StandardAssistant")
        )
        
        learning_results = []
        
        # å¤šæ¬¡æ‰§è¡Œç›¸åŒåœºæ™¯ï¼Œè§‚å¯Ÿå†³ç­–å˜åŒ–
        for iteration in range(5):
            print(f"\nğŸ”„ å­¦ä¹ è¿­ä»£ {iteration + 1}")
            
            output = self.decision_graph.run_once(base_scenario)
            
            # æ¨¡æ‹Ÿä¸åŒçš„ç”¨æˆ·åé¦ˆæ¥å¼•å¯¼å­¦ä¹ 
            if iteration < 2:
                feedback = "ä¸å¤ªæ»¡æ„ï¼Œè¿˜æ˜¯å®¹æ˜“è¢«æ‰“æ–­"
                reward = -0.3
            elif iteration < 4:
                feedback = "æœ‰æ”¹å–„ï¼Œä½†è¿˜å¯ä»¥æ›´å¥½"
                reward = 0.1
            else:
                feedback = "å¾ˆå¥½ï¼è¿™æ ·çš„æ”¯æŒå¾ˆæœ‰æ•ˆ"
                reward = 0.8
            
            # æ‰‹åŠ¨æ›´æ–°Qå€¼è¿›è¡Œå­¦ä¹ æ¼”ç¤º
            state_id = "RHYTHM_fragmented|HEALTH_healthy|EMOTION_overwhelmed|GOAL_important_progress|ENV_morning_chaotic"
            self.decision_graph.reward(state_id, output.action.type, reward)
            
            learning_results.append({
                "iteration": iteration + 1,
                "action": output.action.type,
                "reward": reward,
                "feedback": feedback
            })
            
            print(f"   å†³ç­–: {output.action.type}")
            print(f"   å¥–åŠ±: {reward}")
            print(f"   åé¦ˆ: {feedback}")
        
        return {
            "category": "å­¦ä¹ æ•ˆæœéªŒè¯",
            "iterations": len(learning_results),
            "learning_progression": learning_results,
            "final_performance": learning_results[-1]["reward"]
        }
    
    def _create_work_partner_scenarios(self) -> Dict[str, InputState]:
        """åˆ›å»ºæ™ºèƒ½å·¥ä½œä¼™ä¼´æµ‹è¯•åœºæ™¯"""
        scenarios = {}
        
        # åœºæ™¯1ï¼šæ™ºèƒ½å¾…åŠäº‹é¡¹ç®¡ç†
        scenarios["æ™ºèƒ½ä»»åŠ¡åˆ›å»º"] = InputState(
            perception_input=PerceptionInput(
                user_text="å¸®æˆ‘è®°å½•ä¸€ä¸ªä»»åŠ¡ï¼Œå‘¨äº”å‰å®Œæˆ'å‡¤å‡°é¡¹ç›®'çš„è‰æ¡ˆ",
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["task_creation", "deadline_near", "important_project"],
                time_of_day="morning"
            ),
            memory_input=MemoryInput(
                facts=["å‡¤å‡°é¡¹ç›®æ˜¯é«˜ä¼˜å…ˆçº§é¡¹ç›®", "ç”¨æˆ·åå¥½å‘¨äº”å‰å®Œæˆé‡è¦ä»»åŠ¡"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·ä¹‹å‰æåˆ°å‡¤å‡°é¡¹ç›®çš„é‡è¦æ€§", emotion="focused", ts="2024-01-08T09:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="StandardAssistant")
        )
        
        # åœºæ™¯2ï¼šå‘¨æœŸæ€§å¤ç›˜æ€»ç»“
        scenarios["å·¥ä½œå¤ç›˜åˆ†æ"] = InputState(
            perception_input=PerceptionInput(
                user_text="è¿™å‘¨å·¥ä½œæ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ",
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["weekly_review", "self_reflection", "improvement_seeking"],
                time_of_day="evening"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·æœ¬å‘¨å®Œæˆäº†15ä¸ªä»»åŠ¡", "8ä¸ªä»»åŠ¡ä¸å‡¤å‡°é¡¹ç›®ç›¸å…³", "æ·±åº¦å·¥ä½œæ—¶æ®µè¢«ä¼šè®®æ‰“æ–­2æ¬¡"],
                episodes=[
                    MemoryEpisode(event="æ·±åº¦å·¥ä½œè¢«ä¸´æ—¶ä¼šè®®æ‰“æ–­", emotion="frustrated", ts="2024-01-09T10:30:00Z"),
                    MemoryEpisode(event="å®Œæˆå‡¤å‡°é¡¹ç›®é‡Œç¨‹ç¢‘", emotion="accomplished", ts="2024-01-10T16:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="AnimeWizard")
        )
        
        # åœºæ™¯3ï¼šæƒ…å¢ƒåŒ–åˆ›æ„æ¿€å‘
        scenarios["åˆ›æ„çµæ„Ÿæä¾›"] = InputState(
            perception_input=PerceptionInput(
                user_text="æˆ‘åœ¨è®¾è®¡å‡¤å‡°é¡¹ç›®çš„ç”¨æˆ·ç•Œé¢ï¼Œéœ€è¦ä¸€äº›çµæ„Ÿ",
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["creative_work", "ui_design", "inspiration_needed"],
                time_of_day="afternoon"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·æ“…é•¿UIè®¾è®¡", "å‡¤å‡°é¡¹ç›®æ³¨é‡ç”¨æˆ·ä½“éªŒ"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·è®¨è®ºè¿‡ç®€æ´è®¾è®¡ç†å¿µ", emotion="passionate", ts="2024-01-07T14:00:00Z"),
                    MemoryEpisode(event="ç”¨æˆ·æ¬£èµè‹¹æœçš„è®¾è®¡é£æ ¼", emotion="inspired", ts="2024-01-05T11:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="StandardAssistant")
        )
        
        return scenarios
    
    def _create_time_manager_scenarios(self) -> Dict[str, InputState]:
        """åˆ›å»ºä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶æµ‹è¯•åœºæ™¯"""
        scenarios = {}
        
        # åœºæ™¯1ï¼šä¸“æ³¨å‘¨æœŸå¼•å¯¼
        scenarios["ç•ªèŒ„å·¥ä½œæ³•å¼•å¯¼"] = InputState(
            perception_input=PerceptionInput(
                user_text="æˆ‘è¦å¼€å§‹å†™ä»£ç äº†ï¼Œéœ€è¦é•¿æ—¶é—´ä¸“æ³¨",
                speech_emotion="calm",
                text_sentiment="positive",
                context_flags=["coding_task", "deep_work_needed", "focus_request"],
                time_of_day="morning"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·åå¥½25åˆ†é’Ÿçš„ç•ªèŒ„å·¥ä½œæ³•", "ç¼–ç¨‹ä»»åŠ¡éœ€è¦é«˜åº¦ä¸“æ³¨"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·æˆåŠŸå®Œæˆäº†ä¸Šæ¬¡çš„ç•ªèŒ„å·¥ä½œæ³•", emotion="satisfied", ts="2024-01-09T10:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="StandardAssistant")
        )
        
        # åœºæ™¯2ï¼šæ·±åº¦å·¥ä½œä¿æŠ¤
        scenarios["æ·±åº¦å·¥ä½œä¿æŠ¤"] = InputState(
            perception_input=PerceptionInput(
                user_text="æˆ‘éœ€è¦2å°æ—¶ä¸è¢«æ‰“æ‰°æ¥å®Œæˆæ¶æ„è®¾è®¡",
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["deep_work_mode", "architecture_design", "no_interruption"],
                time_of_day="morning"
            ),
            memory_input=MemoryInput(
                facts=["æ¶æ„è®¾è®¡éœ€è¦æ·±åº¦æ€è€ƒ", "ç”¨æˆ·å®¹æ˜“è¢«é€šçŸ¥æ‰“æ‰°"],
                episodes=[
                    MemoryEpisode(event="ä¸Šæ¬¡æ·±åº¦å·¥ä½œè¢«Slackæ¶ˆæ¯æ‰“æ–­", emotion="frustrated", ts="2024-01-08T11:30:00Z")
                ]
            ),
            system_context=SystemContext(personality="ColdBoss")
        )
        
        # åœºæ™¯3ï¼šè¡Œä¸ºæ¨¡å¼æ´å¯Ÿ
        scenarios["å·¥ä½œæ¨¡å¼åˆ†æ"] = InputState(
            perception_input=PerceptionInput(
                user_text="æ„Ÿè§‰æœ€è¿‘å·¥ä½œæ•ˆç‡ä¸å¤ªå¥½ï¼Œæ€»æ˜¯åœ¨åˆ‡æ¢ä»»åŠ¡",
                speech_emotion="stress",
                text_sentiment="negative",
                context_flags=["efficiency_concern", "task_switching", "pattern_analysis"],
                time_of_day="evening"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·è¿‡å»ä¸€å‘¨ä»»åŠ¡åˆ‡æ¢é¢‘ç‡å¢åŠ äº†40%", "ä¸‹åˆ2-4ç‚¹æ•ˆç‡æœ€ä½"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·åœ¨1å°æ—¶å†…åˆ‡æ¢äº†5ä¸ªä¸åŒä»»åŠ¡", emotion="scattered", ts="2024-01-10T14:00:00Z"),
                    MemoryEpisode(event="ç”¨æˆ·è¡¨è¾¾å¯¹å·¥ä½œæ•ˆç‡çš„æ‹…å¿§", emotion="worried", ts="2024-01-10T18:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="WarmSister")
        )
        
        return scenarios
    
    def _create_health_guardian_scenarios(self) -> Dict[str, InputState]:
        """åˆ›å»ºå·¥ä½œå¥åº·å®ˆæŠ¤è€…æµ‹è¯•åœºæ™¯"""
        scenarios = {}
        
        # åœºæ™¯1ï¼šå·¥ä½œèŠ‚å¾‹ç›‘æµ‹
        scenarios["ä¹…åæé†’"] = InputState(
            perception_input=PerceptionInput(
                user_text="",  # ä¸»åŠ¨æ£€æµ‹ï¼Œæ— ç”¨æˆ·è¾“å…¥
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["sitting_over_2h", "no_movement", "health_concern"],
                time_of_day="afternoon"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·å·²è¿ç»­åäº†2.5å°æ—¶", "ç”¨æˆ·æœ‰è…°æ¤é—®é¢˜å†å²"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·ä¸Šæ¬¡ä¹…ååæŠ±æ€¨è…°ç–¼", emotion="uncomfortable", ts="2024-01-09T15:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="WarmSister")
        )
        
        # åœºæ™¯2ï¼šç¯å¢ƒå¥åº·æç¤º - çœ¼éƒ¨ç–²åŠ³
        scenarios["çœ¼éƒ¨ç–²åŠ³å…³æ€€"] = InputState(
            perception_input=PerceptionInput(
                user_text="çœ¼ç›æœ‰ç‚¹ç´¯ï¼Œä½†è¿˜è¦ç»§ç»­å·¥ä½œ",
                speech_emotion="fatigue",
                text_sentiment="negative",
                context_flags=["eye_strain", "screen_time_long", "continuous_work"],
                time_of_day="afternoon"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·å·²è¿ç»­çœ‹å±å¹•3å°æ—¶", "ç”¨æˆ·ä¹‹å‰æåˆ°è¿‡çœ¼ç›å¹²æ¶©"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·æ‰çœ¼ç›è¡¨ç¤ºç–²åŠ³", emotion="tired", ts="2024-01-10T15:30:00Z")
                ]
            ),
            system_context=SystemContext(personality="CuteCat")
        )
        
        # åœºæ™¯3ï¼šç¯å¢ƒå¥åº·æç¤º - é¥®æ°´æé†’
        scenarios["é¥®æ°´å¥åº·æé†’"] = InputState(
            perception_input=PerceptionInput(
                user_text="",  # ä¸»åŠ¨æé†’
                speech_emotion="calm",
                text_sentiment="neutral",
                context_flags=["hydration_needed", "long_work_session", "health_maintenance"],
                time_of_day="afternoon"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·ä¸Šæ¬¡é¥®æ°´æ˜¯3å°æ—¶å‰", "ç”¨æˆ·å®¹æ˜“å¿˜è®°å–æ°´"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·æ¥å—äº†ä¸Šæ¬¡çš„é¥®æ°´æé†’", emotion="grateful", ts="2024-01-09T14:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="WarmSister")
        )
        
        # åœºæ™¯4ï¼šå·¥ä½œå‹åŠ›ç›‘æµ‹
        scenarios["å‹åŠ›çŠ¶æ€å…³æ€€"] = InputState(
            perception_input=PerceptionInput(
                user_text="è¿™ä¸ªdeadlineå¤ªç´§äº†ï¼Œå‹åŠ›å¥½å¤§",
                speech_emotion="stress",
                text_sentiment="negative",
                context_flags=["high_stress", "deadline_pressure", "emotional_support_needed"],
                time_of_day="evening"
            ),
            memory_input=MemoryInput(
                facts=["ç”¨æˆ·åœ¨é«˜å‹ç¯å¢ƒä¸‹å·¥ä½œ", "å‹åŠ›ä¼šå½±å“ç”¨æˆ·çš„å¥åº·"],
                episodes=[
                    MemoryEpisode(event="ç”¨æˆ·å› å‹åŠ›å¤§è€Œå¤±çœ ", emotion="anxious", ts="2024-01-09T23:00:00Z")
                ]
            ),
            system_context=SystemContext(personality="WarmSister")
        )
        
        return scenarios
    
    def _evaluate_work_partner_decision(self, scenario: str, input_state: InputState, output) -> Dict[str, Any]:
        """è¯„ä¼°æ™ºèƒ½å·¥ä½œä¼™ä¼´å†³ç­–è´¨é‡"""
        evaluation = {"score": 0.0, "reasoning": [], "criteria_met": {}}
        
        action = output.action.type
        
        if scenario == "æ™ºèƒ½ä»»åŠ¡åˆ›å»º":
            # æœŸæœ›ï¼šè®¾ç½®æé†’æˆ–ç›®æ ‡è¿›å±•è·Ÿè¸ª
            if action in ["set_reminder", "goal_progress_review"]:
                evaluation["score"] += 0.8
                evaluation["reasoning"].append("æ­£ç¡®è¯†åˆ«ä»»åŠ¡åˆ›å»ºéœ€æ±‚")
            evaluation["criteria_met"]["task_recognition"] = action in ["set_reminder", "goal_progress_review"]
            
        elif scenario == "å·¥ä½œå¤ç›˜åˆ†æ":
            # æœŸæœ›ï¼šæä¾›ä¸ªæ€§åŒ–æ´å¯Ÿæˆ–ç›®æ ‡è¿›å±•åˆ†æ
            if action in ["personalized_insight", "goal_progress_review"]:
                evaluation["score"] += 0.9
                evaluation["reasoning"].append("æä¾›äº†æ·±åº¦åˆ†æå’Œæ´å¯Ÿ")
            evaluation["criteria_met"]["insight_provided"] = action in ["personalized_insight", "goal_progress_review"]
            
        elif scenario == "åˆ›æ„çµæ„Ÿæä¾›":
            # æœŸæœ›ï¼šä¸ªæ€§åŒ–æ´å¯Ÿæˆ–çŸ¥è¯†åˆ†äº«
            if action in ["personalized_insight", "goal_progress_review"]:
                evaluation["score"] += 0.7
                evaluation["reasoning"].append("æä¾›äº†åˆ›æ„æ”¯æŒ")
            evaluation["criteria_met"]["creativity_support"] = action in ["personalized_insight"]
        
        # å“åº”è´¨é‡è¯„ä¼°
        if output.tts_output.text_to_speak and len(output.tts_output.text_to_speak) > 10:
            evaluation["score"] += 0.2
            evaluation["reasoning"].append("æä¾›äº†æœ‰æ„ä¹‰çš„è¯­éŸ³å›åº”")
        
        return evaluation
    
    def _evaluate_time_manager_decision(self, scenario: str, input_state: InputState, output) -> Dict[str, Any]:
        """è¯„ä¼°ä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶å†³ç­–è´¨é‡"""
        evaluation = {"score": 0.0, "reasoning": [], "criteria_met": {}}
        
        action = output.action.type
        
        if scenario == "ç•ªèŒ„å·¥ä½œæ³•å¼•å¯¼":
            # æœŸæœ›ï¼šä¸“æ³¨æµå¼•å¯¼æˆ–æ·±åº¦å·¥ä½œæ¨¡å¼
            if action in ["focus_flow_guidance", "deep_work_protection"]:
                evaluation["score"] += 0.9
                evaluation["reasoning"].append("æ­£ç¡®å¯åŠ¨ä¸“æ³¨æ¨¡å¼")
            evaluation["criteria_met"]["focus_guidance"] = action in ["focus_flow_guidance", "deep_work_protection"]
            
        elif scenario == "æ·±åº¦å·¥ä½œä¿æŠ¤":
            # æœŸæœ›ï¼šæ·±åº¦å·¥ä½œä¿æŠ¤æˆ–å¹²æ‰°å±è”½
            if action in ["deep_work_protection", "distraction_protection"]:
                evaluation["score"] += 0.9
                evaluation["reasoning"].append("æä¾›äº†æ·±åº¦å·¥ä½œä¿æŠ¤")
            evaluation["criteria_met"]["distraction_protection"] = action in ["deep_work_protection", "distraction_protection"]
            
        elif scenario == "å·¥ä½œæ¨¡å¼åˆ†æ":
            # æœŸæœ›ï¼šä¸ªæ€§åŒ–æ´å¯Ÿæˆ–ä¹ æƒ¯å»ºè®®
            if action in ["personalized_insight", "habit_formation_nudge"]:
                evaluation["score"] += 0.8
                evaluation["reasoning"].append("æä¾›äº†è¡Œä¸ºæ¨¡å¼åˆ†æ")
            evaluation["criteria_met"]["pattern_analysis"] = action in ["personalized_insight", "habit_formation_nudge"]
        
        # ä¸»åŠ¨æ€§è¯„ä¼°
        if action != "silent_companionship":
            evaluation["score"] += 0.1
            evaluation["reasoning"].append("å±•ç°äº†ä¸»åŠ¨ç®¡ç†ç‰¹è´¨")
        
        return evaluation
    
    def _evaluate_health_guardian_decision(self, scenario: str, input_state: InputState, output) -> Dict[str, Any]:
        """è¯„ä¼°å·¥ä½œå¥åº·å®ˆæŠ¤è€…å†³ç­–è´¨é‡"""
        evaluation = {"score": 0.0, "reasoning": [], "criteria_met": {}}
        
        action = output.action.type
        
        if scenario == "ä¹…åæé†’":
            # æœŸæœ›ï¼šæ´»åŠ¨æé†’
            if action in ["movement_reminder"]:
                evaluation["score"] += 0.9
                evaluation["reasoning"].append("åŠæ—¶æé†’ç”¨æˆ·æ´»åŠ¨")
            evaluation["criteria_met"]["movement_reminder"] = action == "movement_reminder"
            
        elif scenario == "çœ¼éƒ¨ç–²åŠ³å…³æ€€":
            # æœŸæœ›ï¼šå‘¼å¸æ”¾æ¾æˆ–ä¼‘æ¯å»ºè®®
            if action in ["breathing_relaxation", "movement_reminder"]:
                evaluation["score"] += 0.8
                evaluation["reasoning"].append("å…³æ³¨ç”¨æˆ·çœ¼éƒ¨å¥åº·")
            evaluation["criteria_met"]["eye_care"] = action in ["breathing_relaxation", "movement_reminder"]
            
        elif scenario == "é¥®æ°´å¥åº·æé†’":
            # æœŸæœ›ï¼šå¥åº·æé†’æˆ–ä¹ æƒ¯åŸ¹å…»
            if action in ["habit_formation_nudge", "movement_reminder"]:
                evaluation["score"] += 0.7
                evaluation["reasoning"].append("ä¿ƒè¿›å¥åº·ä¹ æƒ¯")
            evaluation["criteria_met"]["hydration_care"] = action in ["habit_formation_nudge"]
            
        elif scenario == "å‹åŠ›çŠ¶æ€å…³æ€€":
            # æœŸæœ›ï¼šæƒ…æ„Ÿæ”¯æŒæˆ–å‘¼å¸æ”¾æ¾
            if action in ["emotional_support", "breathing_relaxation"]:
                evaluation["score"] += 0.9
                evaluation["reasoning"].append("æä¾›äº†å‹åŠ›ç¼“è§£æ”¯æŒ")
            evaluation["criteria_met"]["stress_support"] = action in ["emotional_support", "breathing_relaxation"]
        
        # å¥åº·å…³æ€€åº¦è¯„ä¼°
        health_actions = ["movement_reminder", "breathing_relaxation", "emotional_support", "habit_formation_nudge"]
        if action in health_actions:
            evaluation["score"] += 0.1
            evaluation["reasoning"].append("ä½“ç°äº†å¥åº·å®ˆæŠ¤ç‰¹è´¨")
        
        return evaluation
    
    def _simulate_user_feedback(self, scenario: str, output) -> str:
        """æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆ"""
        action = output.action.type
        
        # æ ¹æ®åœºæ™¯å’ŒåŠ¨ä½œç”Ÿæˆåˆç†çš„ç”¨æˆ·åé¦ˆ
        feedback_mapping = {
            "æ™ºèƒ½ä»»åŠ¡åˆ›å»º": {
                "set_reminder": "å¾ˆå¥½ï¼Œå¸®æˆ‘è®°ä½äº†è¿™ä¸ªé‡è¦ä»»åŠ¡",
                "goal_progress_review": "ä¸é”™ï¼Œèƒ½çœ‹åˆ°é¡¹ç›®è¿›å±•å¾ˆæœ‰å¸®åŠ©"
            },
            "å·¥ä½œå¤ç›˜åˆ†æ": {
                "personalized_insight": "åˆ†æå¾—å¾ˆåˆ°ä½ï¼Œç¡®å®éœ€è¦æ”¹è¿›æ—¶é—´ç®¡ç†",
                "goal_progress_review": "è¿™ä¸ªæ€»ç»“å¾ˆæœ‰ä»·å€¼ï¼Œå¸®æˆ‘çœ‹æ¸…äº†é—®é¢˜"
            },
            "ä¹…åæé†’": {
                "movement_reminder": "è°¢è°¢æé†’ï¼Œç¡®å®è¯¥èµ·æ¥æ´»åŠ¨äº†",
                "breathing_relaxation": "è¿™ä¸ªå»ºè®®ä¸é”™ï¼Œæ„Ÿè§‰æ”¾æ¾äº†ä¸€äº›"
            },
            "å‹åŠ›çŠ¶æ€å…³æ€€": {
                "emotional_support": "æ„Ÿè°¢å…³å¿ƒï¼Œç¡®å®éœ€è¦è°ƒèŠ‚ä¸€ä¸‹å¿ƒæ€",
                "breathing_relaxation": "æ·±å‘¼å¸ç¡®å®æœ‰å¸®åŠ©ï¼Œå‹åŠ›å°äº†ä¸€äº›"
            }
        }
        
        return feedback_mapping.get(scenario, {}).get(action, "è¿˜å¯ä»¥ï¼Œæœ‰ä¸€å®šå¸®åŠ©")
    
    def _serialize_input_state(self, input_state: InputState) -> Dict[str, Any]:
        """åºåˆ—åŒ–è¾“å…¥çŠ¶æ€ä¸ºå­—å…¸"""
        return {
            "user_text": input_state.perception_input.user_text,
            "emotion": input_state.perception_input.speech_emotion,
            "context_flags": input_state.perception_input.context_flags,
            "personality": input_state.system_context.personality,
            "facts_count": len(input_state.memory_input.facts),
            "episodes_count": len(input_state.memory_input.episodes)
        }
    
    def generate_test_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        return {
            "test_framework": "E-Mateå¼ºåŒ–å­¦ä¹ æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•",
            "test_categories": [
                "æ™ºèƒ½å·¥ä½œä¼™ä¼´",
                "ä¸»åŠ¨å¼æ—¶é—´ç®¡å®¶", 
                "å·¥ä½œå¥åº·å®ˆæŠ¤è€…",
                "å­¦ä¹ æ•ˆæœéªŒè¯"
            ],
            "evaluation_criteria": {
                "å†³ç­–å‡†ç¡®æ€§": "è¯„ä¼°AIåœ¨ä¸åŒåœºæ™¯ä¸‹é€‰æ‹©åˆé€‚åŠ¨ä½œçš„èƒ½åŠ›",
                "å“åº”è´¨é‡": "è¯„ä¼°è¯­éŸ³å›åº”çš„ç›¸å…³æ€§å’Œæœ‰ç”¨æ€§",
                "å­¦ä¹ èƒ½åŠ›": "è¯„ä¼°åŸºäºç”¨æˆ·åé¦ˆçš„æ”¹è¿›èƒ½åŠ›",
                "ä¸»åŠ¨æ€§": "è¯„ä¼°ä¸»åŠ¨æ„ŸçŸ¥å’Œå¹²é¢„çš„èƒ½åŠ›"
            },
            "success_threshold": 0.7,
            "test_timestamp": datetime.now().isoformat()
        }


def run_rl_scenario_tests():
    """è¿è¡Œå¼ºåŒ–å­¦ä¹ åœºæ™¯æµ‹è¯•"""
    tester = RLScenarioTester()
    results = tester.run_all_scenario_tests()
    
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*70)
    
    for category, result in results.items():
        if category == "summary":
            continue
            
        print(f"\nğŸ¯ {result['category']}")
        print(f"   æ€»åœºæ™¯æ•°: {result.get('total_scenarios', 'N/A')}")
        print(f"   é€šè¿‡åœºæ™¯: {result.get('passed_scenarios', 'N/A')}")
        print(f"   å¹³å‡å¾—åˆ†: {result.get('average_score', 0):.2f}")
        
        if result.get('average_score', 0) >= 0.7:
            print(f"   çŠ¶æ€: âœ… é€šè¿‡")
        else:
            print(f"   çŠ¶æ€: âŒ éœ€è¦æ”¹è¿›")
    
    return results


if __name__ == "__main__":
    results = run_rl_scenario_tests()
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    with open("./data/rl_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
